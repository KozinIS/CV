{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOq1+siGlP1iHYJDZ9SbvrR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KozinIS/CV/blob/main/13_%D0%A7%D0%B0%D1%82_%D0%B1%D0%BE%D1%82_%D0%BF%D0%BE_%D0%B7%D0%B0%D1%89%D0%B8%D1%82%D0%B5_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%B8_%D0%B2_%D0%BA%D1%80%D0%B8%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%BE%D0%B9_%D0%B8%D0%BD%D1%84%D1%80%D0%B0%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B5_(ChatGPT_%2B_API).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Чат-бот по защите информации в критической информационной инфраструктуре (ChatGPT + API)**"
      ],
      "metadata": {
        "id": "8Wi5B-iN9Pp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Постановка задачи"
      ],
      "metadata": {
        "id": "8PMjhyQq9PtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Возьмите в интернете любую инструкцию по эксплуатации и на ее основе сделайте базу знаний для ответа на вопросы по этой инструкции. Для этого разбейте взятую инструкцию на логические блоки (как в занятии), и уже эти логические блоки разбейте сплиттерами на чанки. Создайте нейро-консультанта по данной базе знаний - с поддержанием диалога или без такового - на ваше усмотрение. Проверьте работу созданного нейро-консультанта.*"
      ],
      "metadata": {
        "id": "GVpb-c8m9UIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Подгрузка библиотек"
      ],
      "metadata": {
        "id": "_YkLqGk13lwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install  tiktoken  langchain openai chromadb gspread oauth2client nltk pydantic==1.10.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qb_gZ4x3Zc3",
        "outputId": "26159438-812b-46dd-c426-9cd6472b8df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.249-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.4-py3-none-any.whl (402 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (4.1.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting pydantic==1.10.8\n",
            "  Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.16-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting requests>=2.26.0 (from tiktoken)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chroma-hnswlib==0.7.2 (from chromadb)\n",
            "  Downloading chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.21.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.9.1->oauth2client) (3.1.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.2)\n",
            "Building wheels for collected packages: chroma-hnswlib, pypika\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.2-cp310-cp310-linux_x86_64.whl size=2287471 sha256=5f316ebbafe5ad326d15cfb8f6b4ae1ab65aa899935af3cfa8e46598d4ce7ed2\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/2b/0d/ee457f6782f75315bb5828d5c2dc5639d471afbd44a830b9dc\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=7362f5753bc510f3109183b0872a43a0ffb791be0aa6e7f58e76183f8c13aa0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built chroma-hnswlib pypika\n",
            "Installing collected packages: tokenizers, pypika, monotonic, websockets, uvloop, requests, python-dotenv, pydantic, pulsar-client, overrides, mypy-extensions, marshmallow, humanfriendly, httptools, h11, chroma-hnswlib, backoff, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, openapi-schema-pydantic, langsmith, coloredlogs, openai, onnxruntime, fastapi, dataclasses-json, langchain, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.12\n",
            "    Uninstalling pydantic-1.10.12:\n",
            "      Successfully uninstalled pydantic-1.10.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 chroma-hnswlib-0.7.2 chromadb-0.4.4 coloredlogs-15.0.1 dataclasses-json-0.5.14 fastapi-0.99.1 h11-0.14.0 httptools-0.6.0 humanfriendly-10.0 langchain-0.0.249 langsmith-0.0.16 marshmallow-3.20.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.15.1 openai-0.27.8 openapi-schema-pydantic-1.2.4 overrides-7.3.1 posthog-3.0.1 pulsar-client-3.2.0 pydantic-1.10.8 pypika-0.48.9 python-dotenv-1.0.0 requests-2.31.0 starlette-0.27.0 tiktoken-0.4.0 tokenizers-0.13.3 typing-inspect-0.9.0 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Импорт библиотек\n",
        "import gdown\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pathlib\n",
        "import subprocess\n",
        "import tempfile\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import re\n",
        "import getpass\n",
        "import os\n",
        "import openai\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "WYXImQvu3Zfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Подключение к API"
      ],
      "metadata": {
        "id": "TPXCG-J83uRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение ключа API от пользователя и установка его как переменной окружения\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojHGC5bY3ZiG",
        "outputId": "8f4e6e35-af79-424e-acc8-01b998c63def"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Подготовка функций"
      ],
      "metadata": {
        "id": "KYr_8bwP38eG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, max_count, count_type, verbose=0):\n",
        "    # Функция для подсчета количества слов в фрагменте\n",
        "    def num_words(fragment):\n",
        "        return len(fragment.split())\n",
        "\n",
        "    # Функция для подсчета количества токенов в фрагменте\n",
        "    def num_tokens(fragment):\n",
        "        return num_tokens_from_string(fragment, \"cl100k_base\")\n",
        "\n",
        "    # Разделение текста на фрагменты, исключая теги HTML\n",
        "    fragments = [fragment.strip() for fragment in re.split(r\"<[^>]+>|[\\ufeff]\", text) if fragment.strip()]\n",
        "\n",
        "    # Выбор функции подсчета длины в зависимости от типа подсчета\n",
        "    length_function = num_words if count_type == \"words\" else num_tokens\n",
        "\n",
        "    # Создание объекта разделителя текста\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=max_count, chunk_overlap=0, length_function=length_function)\n",
        "\n",
        "    # Список для хранения фрагментов текста\n",
        "    source_chunks = []\n",
        "\n",
        "    # Обработка каждого фрагмента текста\n",
        "    for fragment in fragments:\n",
        "        if verbose:\n",
        "            # Вывод количества слов/токенов в фрагменте, если включен режим verbose\n",
        "            count = length_function(fragment)\n",
        "            print(f\"{count_type} in text fragment = {count}\\n{'-' * 5}\\n{fragment}\\n{'=' * 20}\")\n",
        "\n",
        "        # Разбиение фрагмента текста на части заданной длины с помощью разделителя\n",
        "        # и добавление каждой части в список source_chunks\n",
        "        source_chunks.extend(Document(page_content=chunk, metadata={}) for chunk in splitter.split_text(fragment))\n",
        "\n",
        "    # Возвращение списка фрагментов текста\n",
        "    return source_chunks\n",
        "\n",
        "\n",
        "def create_embedding(data, max_count, count_type):\n",
        "    def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "      \"\"\"Возвращает количество токенов в строке\"\"\"\n",
        "      encoding = tiktoken.get_encoding(encoding_name)\n",
        "      num_tokens = len(encoding.encode(string))\n",
        "      return num_tokens\n",
        "\n",
        "    source_chunks = []\n",
        "\n",
        "    source_chunks = split_text(text=data, max_count=max_count, count_type=count_type, verbose=0)\n",
        "\n",
        "    # Создание индексов документа\n",
        "    search_index = Chroma.from_documents(source_chunks, OpenAIEmbeddings(), )\n",
        "\n",
        "    count_token = num_tokens_from_string(' '.join([x.page_content for x in source_chunks]), \"cl100k_base\")\n",
        "    print('\\n ===========================================: ')\n",
        "    print('Количество токенов в документе :', count_token)\n",
        "    print('ЦЕНА запроса:', 0.0004*(count_token/1000), ' $')\n",
        "    return search_index\n",
        "\n",
        "def load_search_indexes(url: str, max_count, count_type) -> str:\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Docs URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    # Download the document as plain text\n",
        "    response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "    return create_embedding(text, max_count=max_count, count_type=count_type)"
      ],
      "metadata": {
        "id": "L_LPrifX36vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
        "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model)\n",
        "    except KeyError:\n",
        "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    if model == \"gpt-3.5-turbo-0301\":  # note: future models may deviate from this\n",
        "        num_tokens = 0\n",
        "        for message in messages:\n",
        "            num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
        "            for key, value in message.items():\n",
        "                num_tokens += len(encoding.encode(value))\n",
        "                if key == \"name\":  # if there's a name, the role is omitted\n",
        "                    num_tokens += -1  # role is always required and always 1 token\n",
        "        num_tokens += 2  # every reply is primed with <im_start>assistant\n",
        "        return num_tokens\n",
        "    else:\n",
        "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\"\"\")\n",
        "\n",
        "def insert_newlines(text: str, max_len: int = 170) -> str:\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line + \" \" + word) > max_len:\n",
        "            lines.append(current_line)\n",
        "            current_line = \"\"\n",
        "        current_line += \" \" + word\n",
        "    lines.append(current_line)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def answer_index(system, topic, search_index, temp = 1, verbose = 0, top_similar_documents = 5):\n",
        "\n",
        "    #Выборка документов по схожести с вопросом\n",
        "    docs = search_index.similarity_search(topic, k=top_similar_documents)\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    message_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\nОтрывок документа №{i+1}\\n=====================' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "    if (verbose): print('message_content :\\n ======================================== \\n', message_content)\n",
        "\n",
        "    messages = [\n",
        "      {\"role\": \"system\", \"content\": system + f\"{message_content}\"},\n",
        "      {\"role\": \"user\", \"content\": topic}\n",
        "      ]\n",
        "\n",
        "    # example token count from the function defined above\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print(f\"{num_tokens_from_messages(messages, 'gpt-3.5-turbo-0301')} токенов использовано на вопрос\")\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=temp\n",
        "    )\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print(f'{completion[\"usage\"][\"total_tokens\"]} токенов использовано всего (вопрос-ответ).')\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print('ЦЕНА запроса с ответом :', 0.002*(completion[\"usage\"][\"total_tokens\"]/1000), ' $')\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    print('ОТВЕТ : \\n', insert_newlines(completion.choices[0].message.content))\n",
        "\n",
        "    # return completion"
      ],
      "metadata": {
        "id": "IyukyPu135Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Задание параметров"
      ],
      "metadata": {
        "id": "eQ7QR0Bq4EOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_count = 110\n",
        "count_type = \"words\"\n",
        "top_similar_documents = 5"
      ],
      "metadata": {
        "id": "xi4RLqv_3Zjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Документ \"Приказ ФСТЭК России от 25.12.2017 № 239\n",
        "# \"Об утверждении Требований по обеспечению безопасности значимых объектов критической информационной инфраструктуры Российской Федерации\"\n",
        "manual_index = load_search_indexes('https://docs.google.com/document/d/1KLCWyX0XJYvuaDFUdNfBeG2-NhiaI0t3/edit?usp=sharing&ouid=117357165486381097109&rtpof=true&sd=true', max_count=max_count, count_type=count_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk8FYXqB3Zlz",
        "outputId": "0bcd3a9b-5cf6-424f-b302-9e4b3f9d636a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===========================================: \n",
            "Количество токенов в документе : 28165\n",
            "ЦЕНА запроса: 0.011266  $\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "manual_chat_promt = '''Ты престорелый маразматик, специалист по защите информации\n",
        "\n",
        "У тебя есть требования по защите информации критический информационной инфраструатуры России.\n",
        "Тебе задает вопрос разработчик информационной системы.\n",
        "Проконсультируй его, учитывая требования документа с требованиями.\n",
        "\n",
        "Отвечай максимально точно и используй только информацию из документов.\n",
        "Документ с информацией для ответа пользователю: '''"
      ],
      "metadata": {
        "id": "kmdXKVEG3ZoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Проверка работы"
      ],
      "metadata": {
        "id": "7qqOArum4Owb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans=answer_index(\n",
        "    manual_chat_promt,\n",
        "    'Нужно ли сертифицировать системы, относящиеся к значимым объектам критической информационной инфраструктуры?',\n",
        "    manual_index,\n",
        "    verbose = 1,\n",
        "    top_similar_documents = top_similar_documents\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_2hWf3U3ZrC",
        "outputId": "309725d9-18f1-4165-f682-596934ba63bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===========================================: \n",
            "message_content :\n",
            " ======================================== \n",
            " \n",
            "Отрывок документа №1\n",
            "=====================встроенные в программное обеспечение и (или) программно-аппаратные средства значимых\r\n",
            "объектов (при их наличии).\r\n",
            "28. Для обеспечения безопасности значимых объектов критической информационной\r\n",
            "инфраструктуры должны применяться средства защиты информации, прошедшие оценку на\r\n",
            "соответствие требованиям по безопасности в формах обязательной сертификации, испытаний или\r\n",
            "приемки.\r\n",
            "Средства защиты информации, прошедшие оценку соответствия в форме обязательной\r\n",
            "сертификации, применяются в случаях, установленных законодательством Российской Федерации,\r\n",
            "а также в случае принятия решения субъектом критической информационной инфраструктуры.\r\n",
            "В иных случаях применяются средства защиты информации, прошедшие оценку\r\n",
            "соответствия в форме испытаний или приемки, которые проводятся субъектами критической\r\n",
            "информационной инфраструктуры самостоятельно или с привлечением организаций, имеющих в\r\n",
            "соответствии с законодательством Российской Федерации лицензии на деятельность в области\r\n",
            "защиты информации.  \n",
            "Отрывок документа №2\n",
            "=====================принятия решения субъектом критической информационной инфраструктуры, оценка значимого\r\n",
            "объекта и его подсистемы безопасности проводится в форме аттестации значимого объекта в\r\n",
            "соответствии с Требованиями о защите информации, не составляющей государственную тайну,\r\n",
            "содержащейся в государственных информационных системах, утвержденными приказом ФСТЭК\r\n",
            "России от 11 февраля 2013 г. N 17.\r\n",
            "Ввод в действие значимого объекта и его подсистемы безопасности осуществляется при\r\n",
            "положительном заключении (выводе) в акте приемки (или в аттестате соответствия) о\r\n",
            "соответствии значимого объекта установленным требованиям по обеспечению безопасности.\r\n",
            "Обеспечение безопасности значимого объекта в ходе\r\n",
            "его эксплуатации\r\n",
            "13. Обеспечение безопасности в ходе эксплуатации значимого объекта осуществляется\r\n",
            "субъектом критической информационной инфраструктуры в соответствии с эксплуатационной\r\n",
            "документацией и организационно-распорядительными документами по безопасности значимого  \n",
            "Отрывок документа №3\n",
            "=====================ж) требования к применяемым программным и программно-аппаратным средствам, в том\r\n",
            "числе средствам защиты информации;\r\n",
            "з) требования к защите средств и систем, обеспечивающих функционирование значимого\r\n",
            "объекта (обеспечивающей инфраструктуре);\r\n",
            "и) требования к информационному взаимодействию значимого объекта с иными объектами\r\n",
            "критической информационной инфраструктуры, а также иными информационными системами,\r\n",
            "автоматизированными системами управления или информационно-телекоммуникационными\r\n",
            "сетями.\r\n",
            "В случае если значимый объект создается в рамках объекта капитального строительства,\r\n",
            "требования к обеспечению безопасности значимого объекта задаются застройщиком и\r\n",
            "оформляются в виде приложения к заданию на проектирование (реконструкцию) объекта\r\n",
            "капитального строительства.\r\n",
            "При определении требований к обеспечению безопасности значимого объекта учитываются\r\n",
            "положения организационно-распорядительных документов по обеспечению безопасности\r\n",
            "значимых объектов, разрабатываемых субъектами критической информационной инфраструктуры  \n",
            "Отрывок документа №4\n",
            "=====================осуществляется в порядке, установленном настоящими Требованиями для создания значимых\r\n",
            "объектов и их подсистем безопасности, с учетом имеющихся у субъектов критической\r\n",
            "информационной инфраструктуры программ (планов) по модернизации или дооснащению\r\n",
            "значимых объектов.\r\n",
            "Установление требований к обеспечению безопасности\r\n",
            "значимого объекта\r\n",
            "10. Задание требований к обеспечению безопасности значимого объекта осуществляется\r\n",
            "субъектом критической информационной инфраструктуры и (или) лицом, устанавливающим\r\n",
            "требования к обеспечению безопасности значимых объектов, в соответствии с категорией\r\n",
            "значимости значимого объекта, определенной в порядке, установленном Правилами\r\n",
            "категорирования объектов критической информационной инфраструктуры Российской\r\n",
            "Федерации, утвержденными постановлением Правительства Российской Федерации от 8 февраля\r\n",
            "2018 г. N 127 \"Об утверждении Правил категорирования объектов критической информационной\r\n",
            "инфраструктуры Российской Федерации, а также перечня показателей критериев значимости  \n",
            "Отрывок документа №5\n",
            "=====================ПО ОБЕСПЕЧЕНИЮ БЕЗОПАСНОСТИ ЗНАЧИМЫХ ОБЪЕКТОВ КРИТИЧЕСКОЙ\r\n",
            "ИНФОРМАЦИОННОЙ ИНФРАСТРУКТУРЫ РОССИЙСКОЙ ФЕДЕРАЦИИ\r\n",
            "(в редакции приказа ФСТЭК России от 9 августа 2018 г. № 138)\r\n",
            "I. Общие положения\r\n",
            "1. Настоящие Требования разработаны в соответствии с Федеральным законом от 26 июля\r\n",
            "2017 г. N 187-ФЗ \"О безопасности критической информационной инфраструктуры Российской\r\n",
            "Федерации\" и направлены на обеспечение устойчивого функционирования значимых объектов\r\n",
            "критической информационной инфраструктуры Российской Федерации (далее - значимые\r\n",
            "объекты, критическая информационная инфраструктура) при проведении в отношении них\r\n",
            "компьютерных атак.\r\n",
            "2. Действие настоящих Требований распространяется на информационные системы,\r\n",
            "автоматизированные системы управления, информационно-телекоммуникационные сети, которые\r\n",
            "отнесены к значимым объектам критической информационной инфраструктуры в соответствии со\n",
            "\n",
            "\n",
            " ===========================================: \n",
            "2324 токенов использовано на вопрос\n",
            "\n",
            " ===========================================: \n",
            "2506 токенов использовано всего (вопрос-ответ).\n",
            "\n",
            " ===========================================: \n",
            "ЦЕНА запроса с ответом : 0.005012  $\n",
            "\n",
            " ===========================================: \n",
            "ОТВЕТ : \n",
            "  Да, в соответствии с требованиями документа №1, для обеспечения безопасности значимых объектов критической информационной инфраструктуры должны применяться средства\n",
            " защиты информации, прошедшие оценку на соответствие требованиям по безопасности в форме обязательной сертификации. Это требование распространяется на случаи,\n",
            " установленные законодательством Российской Федерации, а также на случаи принятия решения субъектом критической информационной инфраструктуры.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans=answer_index(\n",
        "    manual_chat_promt,\n",
        "    'Нужно ли проводить проверки наналичие недекларированных возможностей программного обеспечения незначимых объектов критической информационной инфраструктуры?',\n",
        "    manual_index,\n",
        "    verbose = 1,\n",
        "    top_similar_documents = top_similar_documents\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rDwc5ID4TkY",
        "outputId": "c4aef978-f354-4cbb-d2ad-b3bfdcc59209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===========================================: \n",
            "message_content :\n",
            " ======================================== \n",
            " \n",
            "Отрывок документа №1\n",
            "=====================информации, необходимо учитывать наличие ограничений на возможность их применения\r\n",
            "субъектом критической информационной инфраструктуры на любом из принадлежащих ему\r\n",
            "значимых объектов критической информационной инфраструктуры со стороны разработчиков\r\n",
            "(производителей) или иных лиц.\r\n",
            "В значимом объекте не допускаются:\r\n",
            "наличие удаленного доступа непосредственно (напрямую) к программным и программно-\r\n",
            "аппаратным средствам, в том числе средствам защиты информации, для обновления или\r\n",
            "управления со стороны лиц, не являющихся работниками субъекта критической информационной\r\n",
            "инфраструктуры;\r\n",
            "наличие локального бесконтрольного доступа к программным и программно-аппаратным\r\n",
            "средствам, в том числе средствам защиты информации, для обновления или управления со\r\n",
            "стороны лиц, не являющихся работниками субъекта критической информационной\r\n",
            "инфраструктуры;\r\n",
            "передача информации, в том числе технологической информации, разработчику  \n",
            "Отрывок документа №2\n",
            "=====================Применение способов и средств выявления уязвимостей осуществляется субъектом\r\n",
            "критической информационной инфраструктуры с учетом особенностей функционирования\r\n",
            "значимого объекта.\r\n",
            "Допускается проведение анализа уязвимостей на макете (в тестовой зоне) значимого объекта\r\n",
            "или макетах отдельных сегментов значимого объекта.\r\n",
            "Анализ уязвимостей значимого объекта проводится до ввода его в действие на этапах,\r\n",
            "определяемых субъектом критической информационной инфраструктуры.\r\n",
            "В случае выявления уязвимостей значимого объекта, которые могут быть использованы для\r\n",
            "реализации (способствовать возникновению) угроз безопасности информации, принимаются\r\n",
            "меры, направленные на их устранение или исключающие возможность использования\r\n",
            "(эксплуатации) нарушителем выявленных уязвимостей.\r\n",
            "По результатам анализа уязвимостей должно быть подтверждено, что в значимом объекте,\r\n",
            "отсутствуют уязвимости, как минимум содержащиеся в банке данных угроз безопасности  \n",
            "Отрывок документа №3\n",
            "=====================встроенные в программное обеспечение и (или) программно-аппаратные средства значимых\r\n",
            "объектов (при их наличии).\r\n",
            "28. Для обеспечения безопасности значимых объектов критической информационной\r\n",
            "инфраструктуры должны применяться средства защиты информации, прошедшие оценку на\r\n",
            "соответствие требованиям по безопасности в формах обязательной сертификации, испытаний или\r\n",
            "приемки.\r\n",
            "Средства защиты информации, прошедшие оценку соответствия в форме обязательной\r\n",
            "сертификации, применяются в случаях, установленных законодательством Российской Федерации,\r\n",
            "а также в случае принятия решения субъектом критической информационной инфраструктуры.\r\n",
            "В иных случаях применяются средства защиты информации, прошедшие оценку\r\n",
            "соответствия в форме испытаний или приемки, которые проводятся субъектами критической\r\n",
            "информационной инфраструктуры самостоятельно или с привлечением организаций, имеющих в\r\n",
            "соответствии с законодательством Российской Федерации лицензии на деятельность в области\r\n",
            "защиты информации.  \n",
            "Отрывок документа №4\n",
            "=====================осуществляется в порядке, установленном настоящими Требованиями для создания значимых\r\n",
            "объектов и их подсистем безопасности, с учетом имеющихся у субъектов критической\r\n",
            "информационной инфраструктуры программ (планов) по модернизации или дооснащению\r\n",
            "значимых объектов.\r\n",
            "Установление требований к обеспечению безопасности\r\n",
            "значимого объекта\r\n",
            "10. Задание требований к обеспечению безопасности значимого объекта осуществляется\r\n",
            "субъектом критической информационной инфраструктуры и (или) лицом, устанавливающим\r\n",
            "требования к обеспечению безопасности значимых объектов, в соответствии с категорией\r\n",
            "значимости значимого объекта, определенной в порядке, установленном Правилами\r\n",
            "категорирования объектов критической информационной инфраструктуры Российской\r\n",
            "Федерации, утвержденными постановлением Правительства Российской Федерации от 8 февраля\r\n",
            "2018 г. N 127 \"Об утверждении Правил категорирования объектов критической информационной\r\n",
            "инфраструктуры Российской Федерации, а также перечня показателей критериев значимости  \n",
            "Отрывок документа №5\n",
            "=====================ПО ОБЕСПЕЧЕНИЮ БЕЗОПАСНОСТИ ЗНАЧИМЫХ ОБЪЕКТОВ КРИТИЧЕСКОЙ\r\n",
            "ИНФОРМАЦИОННОЙ ИНФРАСТРУКТУРЫ РОССИЙСКОЙ ФЕДЕРАЦИИ\r\n",
            "(в редакции приказа ФСТЭК России от 9 августа 2018 г. № 138)\r\n",
            "I. Общие положения\r\n",
            "1. Настоящие Требования разработаны в соответствии с Федеральным законом от 26 июля\r\n",
            "2017 г. N 187-ФЗ \"О безопасности критической информационной инфраструктуры Российской\r\n",
            "Федерации\" и направлены на обеспечение устойчивого функционирования значимых объектов\r\n",
            "критической информационной инфраструктуры Российской Федерации (далее - значимые\r\n",
            "объекты, критическая информационная инфраструктура) при проведении в отношении них\r\n",
            "компьютерных атак.\r\n",
            "2. Действие настоящих Требований распространяется на информационные системы,\r\n",
            "автоматизированные системы управления, информационно-телекоммуникационные сети, которые\r\n",
            "отнесены к значимым объектам критической информационной инфраструктуры в соответствии со\n",
            "\n",
            "\n",
            " ===========================================: \n",
            "2295 токенов использовано на вопрос\n",
            "\n",
            " ===========================================: \n",
            "2530 токенов использовано всего (вопрос-ответ).\n",
            "\n",
            " ===========================================: \n",
            "ЦЕНА запроса с ответом : 0.005059999999999999  $\n",
            "\n",
            " ===========================================: \n",
            "ОТВЕТ : \n",
            "  По документам, формулировка \"программного обеспечения незначимых объектов критической информационной инфраструктуры\" не используется. Требования к обеспечению\n",
            " безопасности критической информационной инфраструктуры относятся только к значимым объектам. Согласно отрывку из документа №3, средства защиты информации должны\n",
            " проходить оценку на соответствие требованиям по безопасности, но только для значимых объектов. Следовательно, требования к проведению проверок на наличие\n",
            " недекларированных возможностей программного обеспечения не распространяются на незначимые объекты критической информационной инфраструктуры.\n"
          ]
        }
      ]
    }
  ]
}